{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8229377,"sourceType":"datasetVersion","datasetId":4862531}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Directory Tree:\n'''\ndata\n├── classifier             # Directory containing classifier data\n│   ├── inp_classifier_test.pkl    # Pickled file containing test data for classifier input\n│   ├── inp_classifier_train.pkl   # Pickled file containing train data for classifier input\n│   └── inp_classifier_val.pkl     # Pickled file containing validation data for classifier input\n├── embeddings             # Directory containing embeddings data\n│   ├── test_embeddings.pkl    # Pickled file containing embeddings for test data\n│   ├── train_embeddings.pkl   # Pickled file containing embeddings for train data\n│   └── val_embeddings.pkl     # Pickled file containing embeddings for validation data\n├── original               # Directory containing original data\n│   ├── test.json      # JSON file containing original test data\n│   └── train.json     # JSON file containing original train data\n└── processed              # Directory containing processed data\n    ├── test.pkl       # Pickled file containing processed test data\n    ├── train.pkl      # Pickled file containing processed train data\n    └── val.pkl        # Pickled file containing processed validation data\n'''\n\n# Data Formats\n\n'''\n-processed:         \n    ->List(\n        -ID                              # conversation_ID\n        -List(sentences)                 # encoded and padded\n        -List(speakers)                  # one-hot-encoded \n        -List(emotions)                  # label-encoded\n        -List(cause)                     # 1/0 representing whether sentence is cause of emotion or not\n        -List(target_ID,cause_ID)        # Emotion-Cause Pair \n    )\n\n\n-embeddings:         \n    ->List(\n        -ID                              # conversation_ID\n        -List(emotion_embedding)         # emotion capturing embeddings\n        -List(cause_embedding)           # cause capturing embeddings\n        -List(emotion_label)             # ground truth(label-encoded) for emotions\n        -List(emotion_pred)              # predictions(Y/N) for emotions\n        -List(cause_label)               # ground truth(label-encoded) for causes\n        -List(cause_pred)                # predictions(Y/N) for causes\n        -List(target_ID,cause_ID)        # Emotion-Cause Pair \n    )\n    \n    \n-classifier:         \n    ->List(\n        -ID                              # conversation_ID\n        -List(label_pair)                # ground truth(Y/N) for Emotion-Cause Pair \n        -List(label_emotion)             # ground truth(label-encoded) for emotions\n        -List(features)                  # concatenated emotion_embedding+cause_embedding for proposed emotion-cause pair\n        -List(indexes)                   # indexes proposed emotion-cause pair\n    )\n    \n    \n-inp_span:\n    ->Dict(\n        -train\n        -val\n            -ID                          # Conv_ID,Target_ID,Cause_ID\n            -emotion                     # emotion for Traget_ID\n    )\n    \n\n'''\n\npass","metadata":{"execution":{"iopub.status.busy":"2024-04-25T14:01:32.624851Z","iopub.execute_input":"2024-04-25T14:01:32.625601Z","iopub.status.idle":"2024-04-25T14:01:32.642352Z","shell.execute_reply.started":"2024-04-25T14:01:32.625559Z","shell.execute_reply":"2024-04-25T14:01:32.641499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import BertTokenizer, BertModel\nfrom sklearn.metrics.pairwise import cosine_similarity\n\nfrom sklearn.preprocessing import OneHotEncoder\nimport json\nfrom copy import deepcopy as cpy\n\nfrom torch.utils.data import Dataset,DataLoader\nimport torch.nn as nn\n\nfrom sklearn.metrics import *\n\nimport gc\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2024-04-25T14:01:32.643944Z","iopub.execute_input":"2024-04-25T14:01:32.644376Z","iopub.status.idle":"2024-04-25T14:01:39.976015Z","shell.execute_reply.started":"2024-04-25T14:01:32.644345Z","shell.execute_reply":"2024-04-25T14:01:39.975114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DEVICE='cpu'\nRANDOM_SEED = 42\n\nimport os\nimport numpy as np\nimport random\n\nif torch.cuda.is_available():\n    DEVICE='cuda'\n    \ndef seed_all(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    \nseed_all(RANDOM_SEED)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T14:01:39.977193Z","iopub.execute_input":"2024-04-25T14:01:39.977696Z","iopub.status.idle":"2024-04-25T14:01:40.008581Z","shell.execute_reply.started":"2024-04-25T14:01:39.977659Z","shell.execute_reply":"2024-04-25T14:01:40.007727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\n\nclass LoadSave:\n    def __init__(self,path):\n        self.path=path\n\n    def load(self):\n        f = open(self.path, 'rb')\n        loaded_obj=pickle.load(f)\n        f.close()\n        return loaded_obj\n\n    def save(self,here):        \n        f=open(self.path, 'wb')\n        pickle.dump(here,f)\n        f.close()","metadata":{"execution":{"iopub.status.busy":"2024-04-25T14:01:40.011033Z","iopub.execute_input":"2024-04-25T14:01:40.011404Z","iopub.status.idle":"2024-04-25T14:01:40.021105Z","shell.execute_reply.started":"2024-04-25T14:01:40.011373Z","shell.execute_reply":"2024-04-25T14:01:40.020259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil \n\ntry:\n    os.mkdir(\"./data\")\nexcept:\n    pass\n\ntry:\n    os.mkdir(\"./data/classifier\")\nexcept:\n    pass\n\ntry:\n    os.mkdir(\"./data/embeddings\")\nexcept:\n    pass\n\ntry:\n    os.mkdir(\"./data/processed\")\nexcept:\n    pass\n\ntry:\n    os.mkdir(\"./data/span\")\nexcept:\n    pass\n\ntry:\n    os.mkdir(\"./models\")\nexcept:\n    pass\n\ntry:\n    shutil.copytree(\"/kaggle/input/project-dataset/data/original\", \"./data/original\")  \nexcept:\n    pass\n\n\nshutil.copy(\"/kaggle/input/project-dataset/data/test.json\", \"./data/test.json\")  \nshutil.copy(\"/kaggle/input/project-dataset/data/train.json\", \"./data/train.json\") \n\npass","metadata":{"execution":{"iopub.status.busy":"2024-04-25T14:01:40.022381Z","iopub.execute_input":"2024-04-25T14:01:40.022776Z","iopub.status.idle":"2024-04-25T14:01:40.160638Z","shell.execute_reply.started":"2024-04-25T14:01:40.022745Z","shell.execute_reply":"2024-04-25T14:01:40.159700Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install sentence_transformers ","metadata":{"execution":{"iopub.status.busy":"2024-04-25T14:01:40.161972Z","iopub.execute_input":"2024-04-25T14:01:40.162701Z","iopub.status.idle":"2024-04-25T14:01:53.790828Z","shell.execute_reply.started":"2024-04-25T14:01:40.162668Z","shell.execute_reply":"2024-04-25T14:01:53.789884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\nS_Bert=SentenceTransformer(\"all-MiniLM-L6-v2\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-25T14:01:53.792212Z","iopub.execute_input":"2024-04-25T14:01:53.792535Z","iopub.status.idle":"2024-04-25T14:01:58.605730Z","shell.execute_reply.started":"2024-04-25T14:01:53.792507Z","shell.execute_reply":"2024-04-25T14:01:58.604892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Data():\n    def __init__(self,load=True):\n        self.load=load\n        if(load):\n            return\n\n        with open(\"/kaggle/input/project-dataset/data/train.json\",\"r\") as f:\n            data=json.load(f)\n            \n        self.MAX_SENTENCES=35\n        self.UNKNOWN_SPEAKER=\"unknown\"\n        self.PADDED_SPEAKER=\"padded\" #handle_unknown='ignore'\n        self.UNKNOWN_EMOTION=\"undefined\"\n        self.UNKNOWN_CAUSE=2\n        self.emotion_map={\n            self.UNKNOWN_EMOTION:-1,\n            'disgust':0,\n            'joy':1,\n            'surprise':2,\n            'anger':3,\n            'fear':4,\n            'neutral':5,\n            'sadness':6\n        }\n        \n        self.speakers=set()\n        for conv in data:\n            for sent in conv[\"conversation\"]:\n                self.speakers.add(sent[\"speaker\"])\n        self.speakers.add(self.UNKNOWN_SPEAKER)\n        \n        speakers=list(self.speakers)\n        \n        self.speaker_encoder= OneHotEncoder(sparse=False,handle_unknown='ignore')\n        \n        self.speaker_encoder.fit([[label] for label in speakers])\n            \n        \n            \n    def processor(self,data):\n        final_data=[]\n        \n        # {\n        #     \"sentences\"->[],\n        #     \"speaker_onehot\"->[],\n        #     \"emotion(Y/N)\"->[],\n        #     \"cause(Y/N)\"->[],\n        #     \"target_cause(index,index)\"->[],\n        # }\n        \n        for conv in data:\n            temp={\n                \"sentences\":[],\n                \"emotions\":[],\n                \"speakers\":[],\n                \"cause\":[0 for _ in range(self.MAX_SENTENCES)],\n                \"target_cause\":[]\n            }\n            filled=len(conv[\"conversation\"])\n          \n            for sent in conv[\"conversation\"]:\n                temp[\"sentences\"].append(sent[\"text\"])\n                temp[\"emotions\"].append(sent[\"emotion\"])\n                if sent[\"speaker\"] in self.speakers:\n                    temp[\"speakers\"].append([sent[\"speaker\"]])\n                else:\n                    temp[\"speakers\"].append([self.UNKNOWN_SPEAKER])\n                \n            for _ in range(0,self.MAX_SENTENCES-filled):\n                temp[\"sentences\"].append(\" \")\n                temp[\"emotions\"].append(self.UNKNOWN_EMOTION)\n                temp[\"speakers\"].append([self.PADDED_SPEAKER])\n                \n            temp[\"speakers\"]=self.speaker_encoder.transform(temp[\"speakers\"])\n            \n            temp[\"sentences\"]=S_Bert.encode(temp[\"sentences\"],show_progress_bar=False)\n            \n            temp[\"emotions\"]=[self.emotion_map[i] for i in temp[\"emotions\"]]\n            \n            for pair in conv[\"emotion-cause_pairs\"]:\n                temp[\"cause\"][int(pair[\"cause_id\"])-1]=1\n                temp[\"target_cause\"].append([int(pair[\"target_id\"]),int(pair[\"cause_id\"])])\n                \n            for padd_idx in range(filled,self.MAX_SENTENCES):\n                temp[\"cause\"][padd_idx]=self.UNKNOWN_CAUSE\n                \n                \n            temp[\"sentences\"]=temp[\"sentences\"][:self.MAX_SENTENCES]\n            temp[\"emotions\"]=np.array(temp[\"emotions\"][:self.MAX_SENTENCES])\n            temp[\"speakers\"]=temp[\"speakers\"][:self.MAX_SENTENCES]\n            temp[\"cause\"]=np.array(temp[\"cause\"][:self.MAX_SENTENCES])\n            temp[\"target_cause\"]=np.array(temp[\"target_cause\"])\n            \n            temp[\"ID\"]=int(conv[\"conversation_ID\"])\n                \n            final_data.append(cpy(temp))\n           \n        return final_data\n            \n\n    def train_data(self): \n        if(self.load):\n            temp=LoadSave(\"/kaggle/input/project-dataset/data/processed/train_processed.pkl\")\n            return temp.load()\n        with open(\"/kaggle/input/project-dataset/data/train.json\",\"r\") as f:\n            data=json.load(f)\n            \n        return self.processor(data)\n\n            \n    def val_data(self):\n        if(self.load):\n            temp=LoadSave(\"/kaggle/input/project-dataset/data/processed/val_processed.pkl\")\n            return temp.load()\n        with open(\"/kaggle/input/project-dataset/data/test.json\",\"r\") as f:\n            data=json.load(f)\n        \n        return self.processor(data)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-25T14:01:58.606883Z","iopub.execute_input":"2024-04-25T14:01:58.607178Z","iopub.status.idle":"2024-04-25T14:01:58.628008Z","shell.execute_reply.started":"2024-04-25T14:01:58.607153Z","shell.execute_reply":"2024-04-25T14:01:58.627110Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=Data(False)\n\n# data=Data(True) #yeh wala hain!!!","metadata":{"execution":{"iopub.status.busy":"2024-04-25T14:01:58.629144Z","iopub.execute_input":"2024-04-25T14:01:58.629417Z","iopub.status.idle":"2024-04-25T14:01:58.698990Z","shell.execute_reply.started":"2024-04-25T14:01:58.629394Z","shell.execute_reply":"2024-04-25T14:01:58.698192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train=data.train_data()\nval=data.val_data()","metadata":{"execution":{"iopub.status.busy":"2024-04-25T14:01:58.702551Z","iopub.execute_input":"2024-04-25T14:01:58.702811Z","iopub.status.idle":"2024-04-25T14:02:24.867569Z","shell.execute_reply.started":"2024-04-25T14:01:58.702790Z","shell.execute_reply":"2024-04-25T14:02:24.866582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp=LoadSave(\"./data/processed/train_processed.pkl\")\ntemp.save(train)\n\ntemp=LoadSave(\"./data/processed/val_processed.pkl\")\ntemp.save(val)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T14:02:24.868686Z","iopub.execute_input":"2024-04-25T14:02:24.868965Z","iopub.status.idle":"2024-04-25T14:02:25.200231Z","shell.execute_reply.started":"2024-04-25T14:02:24.868942Z","shell.execute_reply":"2024-04-25T14:02:25.199118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mapper={}\n\nclass Samples(Dataset):\n    def __init__(self,data):\n        self.data=data\n    \n        for i in range(len(self.data)):\n            mapper[int(self.data[i][\"ID\"])]=self.data[i].pop(\"target_cause\",[])   \n      \n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self,idx):\n        return self.data[idx]","metadata":{"execution":{"iopub.status.busy":"2024-04-25T14:02:25.201597Z","iopub.execute_input":"2024-04-25T14:02:25.202469Z","iopub.status.idle":"2024-04-25T14:02:25.210025Z","shell.execute_reply.started":"2024-04-25T14:02:25.202433Z","shell.execute_reply":"2024-04-25T14:02:25.208847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE=4\n\ntrain_loader=DataLoader(Samples(train),batch_size=BATCH_SIZE)\nval_loader=DataLoader(Samples(val),batch_size=BATCH_SIZE)\n\ntarget_cause_map=cpy(mapper)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T14:02:25.211332Z","iopub.execute_input":"2024-04-25T14:02:25.211742Z","iopub.status.idle":"2024-04-25T14:02:25.238533Z","shell.execute_reply.started":"2024-04-25T14:02:25.211709Z","shell.execute_reply":"2024-04-25T14:02:25.237346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Emotion_Rep(nn.Module):\n    def __init__(self):\n        super().__init__()\n        SIZE=1024\n#         self.lstm= nn.LSTM(input_size=384, hidden_size=SIZE, batch_first=True, bidirectional=True)\n        self.lstm= nn.LSTM(input_size=384+283, hidden_size=SIZE, batch_first=True, bidirectional=True)\n        \n        self.layer= nn.Sequential(\n            nn.Linear(SIZE*2, 512),\n            nn.LeakyReLU(),\n            nn.Linear(512, 128),\n            nn.LeakyReLU(),\n            nn.Linear(128, 2),\n        )\n        \n#     def forward(self, x):\n#         x_ = self.lstm(x)[0]\n#         x_ = self.layer(x_)\n\n#         return x_\n\n#     def embedding(self,x):\n#         return self.lstm(x)[0]\n  \n\n    def forward(self, x, x1):\n        x=torch.cat((x,x1),dim=2)\n        x_ = self.lstm(x)[0]\n        x_ = self.layer(x_)\n\n        return x_\n    \n    def embedding(self,x, x1):\n        x=torch.cat((x,x1),dim=2)\n        return self.lstm(x)[0]\n    \nclass Cause_Rep(nn.Module):\n    def __init__(self):\n        SIZE=1024\n        super().__init__()\n#         self.lstm= nn.LSTM(input_size=384, hidden_size=SIZE, batch_first=True, bidirectional=True)\n        self.lstm= nn.LSTM(input_size=384+283, hidden_size=SIZE, batch_first=True, bidirectional=True)\n        \n        self.layer= nn.Sequential(\n            nn.Linear(SIZE*2, 512),\n            nn.LeakyReLU(),\n            nn.Linear(512, 128),\n            nn.LeakyReLU(),\n            nn.Linear(128, 2),\n        )\n        \n#     def forward(self, x):\n#         x_ = self.lstm(x)[0]\n#         x_ = self.layer(x_)\n\n#         return x_\n    \n#     def embedding(self,x):\n#         return self.lstm(x)[0]\n\n\n    def forward(self, x, x1):\n        x=torch.cat((x,x1),dim=2)\n        x_ = self.lstm(x)[0]\n        x_ = self.layer(x_)\n\n        return x_\n    \n    def embedding(self,x, x1):\n        x=torch.cat((x,x1),dim=2)\n        return self.lstm(x)[0]","metadata":{"execution":{"iopub.status.busy":"2024-04-25T14:02:25.239830Z","iopub.execute_input":"2024-04-25T14:02:25.240215Z","iopub.status.idle":"2024-04-25T14:02:25.259275Z","shell.execute_reply.started":"2024-04-25T14:02:25.240183Z","shell.execute_reply":"2024-04-25T14:02:25.255911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotion_model=Emotion_Rep().to(DEVICE)\ncause_model=Cause_Rep().to(DEVICE)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T14:02:25.261185Z","iopub.execute_input":"2024-04-25T14:02:25.261565Z","iopub.status.idle":"2024-04-25T14:02:25.634629Z","shell.execute_reply.started":"2024-04-25T14:02:25.261532Z","shell.execute_reply":"2024-04-25T14:02:25.633466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion_emotion = nn.CrossEntropyLoss()\ncriterion_cause = nn.CrossEntropyLoss()\n\noptimizer= torch.optim.Adam(list(emotion_model.parameters())+list(cause_model.parameters()), lr=1e-3)\n# optimizer= torch.optim.Adam(emotion_model.parameters(), lr=1e-3)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T14:02:25.635843Z","iopub.execute_input":"2024-04-25T14:02:25.636200Z","iopub.status.idle":"2024-04-25T14:02:25.641814Z","shell.execute_reply.started":"2024-04-25T14:02:25.636174Z","shell.execute_reply":"2024-04-25T14:02:25.640858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logger={\"emotion\":[],\"cause\":[]}\n\nprint(\"Training\\n\")\nNUM_EPOCHS=5\n\nfor i in range(NUM_EPOCHS):\n    \n    train_loss=0\n    val_loss=0\n    batch_train=0\n    batch_val=0\n    \n    emotion_model.train()\n    cause_model.train()\n    \n    labels={\n        \"emotion\":{\n            \"train\":{\n                \"pred\":[],\n                \"true\":[]\n            },\n            \"val\":{\n                \"pred\":[],\n                \"true\":[]\n            }\n        },\n        \"cause\":{\n            \"train\":{\n                \"pred\":[],\n                \"true\":[]\n            },\n            \"val\":{\n                \"pred\":[],\n                \"true\":[]\n            }\n        }\n    }\n    \n    for batch in train_loader:\n        \n        inp=batch[\"sentences\"].to(DEVICE)\n        emotion_ids=batch[\"emotions\"].to(DEVICE)\n        cause_ids=batch[\"cause\"].to(DEVICE)\n        spk=batch[\"speakers\"].to(torch.long).to(DEVICE)\n\n#         print(\"EMOTION\")\n        outputs_emotion=emotion_model(inp,spk)\n#         outputs_emotion=emotion_model(inp,spk)\n#         connection=emotion_model.embedding(inp)\n        \n\n        outputs_emotion=outputs_emotion.view(-1, 2).float()\n        emotion_ids=emotion_ids.view(-1).to(torch.long)\n\n\n        mask=emotion_ids!=-1\n        outputs_emotion=outputs_emotion[mask]\n        emotion_ids=emotion_ids[mask]\n        \n        mask=emotion_ids!=5\n        emotion_ids[mask]=1\n        mask=emotion_ids==5\n        emotion_ids[mask]=0\n        \n        labels[\"emotion\"][\"train\"][\"true\"]+=emotion_ids.cpu().detach().numpy().tolist()\n        temp=torch.argmax(outputs_emotion,dim=1)\n        labels[\"emotion\"][\"train\"][\"pred\"]+=temp.cpu().detach().numpy().tolist()\n        loss_emotion=criterion_emotion(outputs_emotion,emotion_ids)\n\n\n#         print(\"CAUSE\")\n    \n        outputs_cause=cause_model(inp,spk)\n\n        outputs_cause=outputs_cause.view(-1, 2).float()\n        cause_ids=cause_ids.view(-1).to(torch.long)\n\n        mask= cause_ids!=2\n        outputs_cause=outputs_cause[mask]\n        cause_ids=cause_ids[mask]\n        \n        labels[\"cause\"][\"train\"][\"true\"]+=cause_ids.cpu().detach().numpy().tolist()\n        temp=torch.argmax(outputs_cause,dim=1)\n        labels[\"cause\"][\"train\"][\"pred\"]+=temp.cpu().detach().numpy().tolist()\n\n        loss_cause=criterion_cause(outputs_cause,cause_ids)\n        \n        E_size=emotion_ids.shape[0]\n        C_size=cause_ids.shape[0]        \n        \n        net_loss=loss_emotion/E_size+loss_cause/C_size \n        \n        train_loss+=net_loss.item()\n        batch_train+=1\n\n        optimizer.zero_grad()\n        net_loss.backward()\n        optimizer.step()\n\n        \n    train_loss/=batch_train\n    \n    \n    emotion_model.eval()\n    cause_model.eval()\n    \n    for batch in val_loader:\n\n        inp=batch[\"sentences\"].to(DEVICE)\n        emotion_ids=batch[\"emotions\"].to(DEVICE)\n        cause_ids=batch[\"cause\"].to(DEVICE)\n        spk=batch[\"speakers\"].to(torch.long).to(DEVICE)\n\n        \n#         print(\"EMOTION_VAL\")\n        outputs_emotion=emotion_model(inp,spk)\n#         outputs_emotion=emotion_model(inp,spk)\n    \n#         connection=emotion_model.embedding(inp)\n\n        outputs_emotion=outputs_emotion.view(-1, 2).float()\n        emotion_ids=emotion_ids.view(-1).to(torch.long)\n\n        mask=emotion_ids!=-1\n        outputs_emotion=outputs_emotion[mask]\n        emotion_ids=emotion_ids[mask]\n        \n        mask=emotion_ids!=5\n        emotion_ids[mask]=1\n        mask=emotion_ids==5\n        emotion_ids[mask]=0\n\n        labels[\"emotion\"][\"val\"][\"true\"]+=emotion_ids.cpu().detach().numpy().tolist()\n        temp=torch.argmax(outputs_emotion,dim=1)\n        labels[\"emotion\"][\"val\"][\"pred\"]+=temp.cpu().detach().numpy().tolist()\n        loss_emotion=criterion_emotion(outputs_emotion,emotion_ids)\n\n\n#         print(\"CAUSE_VAL\")\n        outputs_cause=cause_model(inp,spk)\n\n        outputs_cause=outputs_cause.view(-1, 2).float()\n        cause_ids=cause_ids.view(-1).to(torch.long)\n\n        mask= cause_ids!=2\n        outputs_cause=outputs_cause[mask]\n        cause_ids=cause_ids[mask]\n\n        labels[\"cause\"][\"val\"][\"true\"]+=cause_ids.cpu().detach().numpy().tolist()\n        temp=torch.argmax(outputs_cause,dim=1)\n        labels[\"cause\"][\"val\"][\"pred\"]+=temp.cpu().detach().numpy().tolist()\n        loss_cause=criterion_cause(outputs_cause,cause_ids)\n        \n        \n        E_size=emotion_ids.shape[0]\n        C_size=cause_ids.shape[0]\n        net_loss=loss_emotion/E_size+loss_cause/C_size \n        \n        val_loss+=net_loss.item()\n        batch_val+=1\n\n        \n    val_loss/=batch_val\n    \n    print(\"Epoch->\",i)\n    print(\"\\tTrain->\",train_loss,\"\\tVal->\",val_loss)\n    \n#     print(labels)\n    \n#     print(\"\\tTrain_emotion\")\n#     print(classification_report(labels[\"emotion\"][\"train\"][\"true\"],labels[\"emotion\"][\"train\"][\"pred\"]))\n#     print(\"\\tVal_emotion\")\n#     print(classification_report(labels[\"emotion\"][\"val\"][\"true\"],labels[\"emotion\"][\"val\"][\"pred\"]))\n#     print(\"\\tTrain_cause\")\n#     print(classification_report(labels[\"cause\"][\"train\"][\"true\"],labels[\"cause\"][\"train\"][\"pred\"]))\n#     print(\"\\tVal_cause\")\n#     print(classification_report(labels[\"cause\"][\"val\"][\"true\"],labels[\"cause\"][\"val\"][\"pred\"]))\n#     print(\"\\n\\n\\n\")\n\nprint(\"Trained\\n\")\n# print(logger)\n\n# with open(\"./models/Cause_Rep.pt\",\"wb\") as f: \n#     torch.save(cause_model,f)\n    \n# with open(\"./models/Emotion_Rep.pt\",\"wb\") as f: \n#     torch.save(emotion_model,f)\n    \ntorch.save(emotion_model,\"Emotion_Rep.pt\")\ntorch.save(cause_model,\"Cause_Rep.pt\")","metadata":{"execution":{"iopub.status.busy":"2024-04-25T14:02:58.652529Z","iopub.execute_input":"2024-04-25T14:02:58.652878Z","iopub.status.idle":"2024-04-25T14:02:58.884457Z","shell.execute_reply.started":"2024-04-25T14:02:58.652853Z","shell.execute_reply":"2024-04-25T14:02:58.883106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_embeddings_loader=DataLoader(Samples(train),batch_size=1)\nval_embeddings_loader=DataLoader(Samples(val),batch_size=1)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_embeddings=[]\nval_embeddings=[]\n\nprint(\"Generating embeddings\\n\")\n\n\nemotion_model.eval()\ncause_model.eval()\n\n\nfor batch in train_embeddings_loader:\n    temp={}\n    temp[\"ID\"]=int(batch[\"ID\"][0].item())\n    inp=batch[\"sentences\"].to(DEVICE)\n    emotion_ids=batch[\"emotions\"].to(DEVICE)\n    cause_ids=batch[\"cause\"].to(DEVICE)\n    spk=batch[\"speakers\"].to(torch.long).to(DEVICE)\n    \n    mask=emotion_ids!=-1\n    emotion_ids=emotion_ids[mask]\n    cause_ids=cause_ids[mask]\n    inp=torch.unsqueeze(inp[mask],0)\n    spk=torch.unsqueeze(spk[mask],0)\n    \n    temp[\"emotion_label\"]=emotion_ids.detach().cpu().numpy()\n    temp[\"cause_label\"]=cause_ids.detach().cpu().numpy()\n    temp[\"emotion_embedding\"]=emotion_model.embedding(inp,spk).squeeze(dim=0).detach().cpu().numpy()\n    temp[\"cause_embedding\"]=cause_model.embedding(inp,spk).squeeze(dim=0).detach().cpu().numpy()\n    \n\n    outputs_emotion=emotion_model(inp,spk)\n    outputs_emotion=outputs_emotion.view(-1, 2).float()\n    emotion_ids=emotion_ids.view(-1).to(torch.long)\n    \n    opt=torch.argmax(outputs_emotion,dim=1).cpu().detach().numpy().tolist()\n    temp[\"emotion_pred\"]=opt\n    \n    \n    \n    outputs_cause=cause_model(inp,spk)\n    outputs_cause=outputs_cause.view(-1, 2).float()\n    cause_ids=cause_ids.view(-1).to(torch.long)\n\n    \n    opt=torch.argmax(outputs_cause,dim=1).cpu().detach().numpy().tolist()\n    temp[\"cause_pred\"]=opt\n\n    temp[\"target_cause\"]=target_cause_map[temp[\"ID\"]]\n\n    \n    train_embeddings.append(temp)\n    \nprint(\"\\tGenerated Train\")\n    \n\nfor batch in val_embeddings_loader:\n    temp={}\n    temp[\"ID\"]=int(batch[\"ID\"][0].item())\n    inp=batch[\"sentences\"].to(DEVICE)\n    emotion_ids=batch[\"emotions\"].to(DEVICE)\n    cause_ids=batch[\"cause\"].to(DEVICE)\n    spk=batch[\"speakers\"].to(torch.long).to(DEVICE)\n    \n    mask=emotion_ids!=-1\n    emotion_ids=emotion_ids[mask]\n    cause_ids=cause_ids[mask]\n    inp=torch.unsqueeze(inp[mask],0)\n    spk=torch.unsqueeze(spk[mask],0)\n    \n    temp[\"emotion_label\"]=emotion_ids.detach().cpu().numpy()\n    temp[\"cause_label\"]=cause_ids.detach().cpu().numpy()\n    temp[\"emotion_embedding\"]=emotion_model.embedding(inp,spk).squeeze(dim=0).detach().cpu().numpy()\n    temp[\"cause_embedding\"]=cause_model.embedding(inp,spk).squeeze(dim=0).detach().cpu().numpy()\n    \n\n    outputs_emotion=emotion_model(inp,spk)\n    outputs_emotion=outputs_emotion.view(-1, 2).float()\n    emotion_ids=emotion_ids.view(-1).to(torch.long)\n\n    \n    opt=torch.argmax(outputs_emotion,dim=1).cpu().detach().numpy().tolist()\n    temp[\"emotion_pred\"]=opt\n    \n    \n    \n    outputs_cause=cause_model(inp,spk)\n    outputs_cause=outputs_cause.view(-1, 2).float()\n    cause_ids=cause_ids.view(-1).to(torch.long)\n\n    \n    opt=torch.argmax(outputs_cause,dim=1).cpu().detach().numpy().tolist()\n    temp[\"cause_pred\"]=opt\n\n    temp[\"target_cause\"]=target_cause_map[temp[\"ID\"]]\n\n    \n    val_embeddings.append(temp)\n\n\nprint(\"\\tGenerated Val\")\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntemp=LoadSave(\"./data/embeddings/train_embeddings.pkl\")\ntemp.save(train_embeddings)\n\ntemp=LoadSave(\"./data/embeddings/val_embeddings.pkl\")\ntemp.save(val_embeddings)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_embeddings=[]\n# val_embeddings=[]\n\n\n# temp=LoadSave(\"/kaggle/input/project-dataset/data/embeddings/train_embeddings.pkl\")\n# train_embeddings=temp.load()\n\n# temp=LoadSave(\"/kaggle/input/project-dataset/data/embeddings/val_embeddings.pkl\")\n# val_embeddings=temp.load()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_conversations=[]\nval_conversations=[]\n\nfor conv in train_embeddings:\n    temp={\n        \"label_pair\":[],\n        \"label_emotion\":[],\n        \"features\":[],\n        \"indexes\":[]\n    }\n    \n    pairs={}\n    \n    em_mask=np.array(conv[\"emotion_pred\"])==1\n    ca_mask=np.array(conv[\"cause_pred\"])==1\n    \n    em_ids=np.where(em_mask==True)[0]\n    ca_ids=np.where(ca_mask==True)[0]\n\n    \n    em_embed=conv[\"emotion_embedding\"][em_mask]\n    ca_embed=conv[\"cause_embedding\"][ca_mask]\n        \n    for i in conv[\"target_cause\"]:\n        pairs[tuple(i.tolist())]=True\n\n    \n    for em,em_id in zip(em_embed,em_ids):\n        for ca,ca_id in zip(ca_embed,ca_ids):\n            temp[\"features\"].append(np.concatenate([em,ca]))\n            temp[\"label_emotion\"].append(conv[\"emotion_label\"][em_id])\n            \n            here=(em_id+1,ca_id+1)\n            try:\n                pairs[here]\n                temp[\"label_pair\"].append(1)\n            except KeyError:\n                temp[\"label_pair\"].append(0)\n            temp[\"indexes\"].append([conv[\"ID\"],em_id+1,ca_id+1])\n                            \n    temp[\"features\"]=np.array(temp[\"features\"])\n    temp[\"label_emotion\"]=np.array(temp[\"label_emotion\"])\n    temp['label_pair']=np.array(temp['label_pair'])\n    temp[\"indexes\"]=np.array(temp[\"indexes\"])\n    train_conversations.append(temp)\n    \n    \n           \n    \nfor conv in val_embeddings:\n    temp={\n        \"label_pair\":[],\n        \"label_emotion\":[],\n        \"features\":[],\n        \"indexes\":[]\n    }\n    \n    pairs={}\n    \n    em_mask=np.array(conv[\"emotion_pred\"])==1\n    ca_mask=np.array(conv[\"cause_pred\"])==1\n    \n    em_ids=np.where(em_mask==True)[0]\n    ca_ids=np.where(ca_mask==True)[0]\n\n    \n    em_embed=conv[\"emotion_embedding\"][em_mask]\n    ca_embed=conv[\"cause_embedding\"][ca_mask]\n        \n    for i in conv[\"target_cause\"]:\n        pairs[tuple(i.tolist())]=True\n\n    \n    for em,em_id in zip(em_embed,em_ids):\n        for ca,ca_id in zip(ca_embed,ca_ids):\n            temp[\"features\"].append(np.concatenate([em,ca]))\n            temp[\"label_emotion\"].append(conv[\"emotion_label\"][em_id])\n            \n            here=(em_id+1,ca_id+1)\n            try:\n                pairs[here]\n                temp[\"label_pair\"].append(1)\n            except KeyError:\n                temp[\"label_pair\"].append(0)\n            temp[\"indexes\"].append([conv[\"ID\"],em_id+1,ca_id+1])\n                            \n    temp[\"features\"]=np.array(temp[\"features\"])\n    temp[\"label_emotion\"]=np.array(temp[\"label_emotion\"])\n    temp['label_pair']=np.array(temp['label_pair'])\n    temp[\"indexes\"]=np.array(temp[\"indexes\"])\n            \n    val_conversations.append(temp)\n        \n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp=LoadSave(\"./data/classifier/inp_classifier_train.pkl\")\ntemp.save(train_conversations)\n\ntemp=LoadSave(\"./data/classifier/inp_classifier_val.pkl\")\ntemp.save(val_conversations)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_conversations=[]\n# val_conversations=[]\n\n# temp=LoadSave(\"/kaggle/input/project-dataset/data/classifier/inp_classifier_train.pkl\")\n# train_conversations=temp.load()\n\n# temp=LoadSave(\"/kaggle/input/project-dataset/data/classifier/inp_classifier_val.pkl\")\n# val_conversations=temp.load()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_pair_train=[]\nlabel_emotion_train=[]\nfeatures_train=[]\nidentifier_train=[]\n\nlabel_pair_val=[]\nlabel_emotion_val=[]\nfeatures_val=[]\nidentifier_val=[]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Samples_Classifier(Dataset):\n    def __init__(self,feature,pair,emotion,identifier):\n        self.feature=torch.Tensor(feature)\n        self.pair=torch.tensor(pair)\n        self.emotion=torch.tensor(emotion)\n        self.identifier=torch.tensor(identifier)\n        \n    def __len__(self):\n        return len(self.feature)\n    \n    def __getitem__(self,idx):\n        return self.feature[idx],self.pair[idx],self.emotion[idx],self.identifier[idx]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE=16\nprint(\"BatchMaking\")\n\nfor i in train_conversations:\n    label_pair_train+=i[\"label_pair\"].tolist()\n    label_emotion_train+=i[\"label_emotion\"].tolist()\n    features_train+=i[\"features\"].tolist()\n    identifier_train+=i[\"indexes\"].tolist()\n    \ntrain_loader=DataLoader(Samples_Classifier(features_train,label_pair_train,label_emotion_train,identifier_train),batch_size=BATCH_SIZE)\n\n# del label_pair_train\n# del label_emotion_train\n# del features_train\ngc.collect()\n    \n    \nfor i in val_conversations:\n    label_pair_val+=i[\"label_pair\"].tolist()\n    label_emotion_val+=i[\"label_emotion\"].tolist()\n    features_val+=i[\"features\"].tolist()\n    identifier_val+=i[\"indexes\"].tolist()\n    \nval_loader=DataLoader(Samples_Classifier(features_val,label_pair_val,label_emotion_val,identifier_val),batch_size=BATCH_SIZE)\n\n# del label_pair_val\n# del label_emotion_val\n# del features_val\ngc.collect()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Classify_Pair(nn.Module):\n    def __init__(self, input_size, output_size=2):\n        super().__init__()\n        self.layer = nn.Sequential(\n            nn.Linear(input_size, 2048),\n            nn.LeakyReLU(),\n            nn.Linear(2048, 1024),\n            nn.LeakyReLU(),\n            nn.Linear(1024, 512),\n            nn.LeakyReLU(),\n            nn.Linear(512, 256),\n            nn.LeakyReLU(),\n            nn.Linear(256, output_size)\n        )\n    \n    def forward(self, x):\n        return self.layer(x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_pair = Classify_Pair(4096).to(DEVICE)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model_pair.parameters(), lr=1e-5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Training_Classify_Pair\\n\")\nNUM_EPOCHS=15\n\nfor i in range(NUM_EPOCHS):\n    labels={\n        \"train\":{\n            \"pred\":[],\n            \"true\":[]\n        },\n        \"val\":{\n            \"pred\":[],\n            \"true\":[]\n        }\n    }\n    \n    train_loss=0\n    val_loss=0\n    batch_train=0\n    batch_val=0\n    \n    model_pair.train()\n    \n    \n    for feature,pair,emotion,_ in train_loader:\n\n        feature=feature.to(DEVICE)\n        pair=pair.to(DEVICE)\n        emotion=emotion.to(DEVICE)\n\n        outputs=model_pair(feature)\n\n        outputs=outputs.view(-1, 2).float()\n        emotion=emotion.view(-1).to(torch.long)\n        pair=pair.view(-1).to(torch.long)\n        \n        labels[\"train\"][\"true\"]+=pair.cpu().detach().numpy().tolist()\n        temp=torch.argmax(outputs,dim=1)\n        labels[\"train\"][\"pred\"]+=temp.cpu().detach().numpy().tolist()\n\n        loss=criterion(outputs,pair)\n        \n        batch_train+=1\n\n        train_loss+=loss.item()\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    \n    model_pair.eval()\n    \n    for feature,pair,emotion,_ in val_loader:\n\n        feature=feature.to(DEVICE)\n        pair=pair.to(DEVICE)\n        emotion=emotion.to(DEVICE)\n\n        outputs=model_pair(feature)\n        \n\n        outputs=outputs.view(-1, 2).float()\n        emotion=emotion.view(-1).to(torch.long)\n        pair=pair.view(-1).to(torch.long)\n\n        \n        labels[\"val\"][\"true\"]+=pair.cpu().detach().numpy().tolist()\n        temp=torch.argmax(outputs,dim=1)\n        labels[\"val\"][\"pred\"]+=temp.cpu().detach().numpy().tolist()\n\n\n        loss=criterion(outputs,pair)\n\n        val_loss+=loss.item()\n        \n        batch_val+=1\n\n    \n    print(\"Epoch->\",i)\n    print(\"\\tTrain->\",train_loss/batch_train,\"\\tVal->\",val_loss/batch_val)\n    \n    print(\"\\tTrain\")\n    print(np.unique(labels[\"train\"][\"pred\"],return_counts=True))\n    print(classification_report(labels[\"train\"][\"true\"],labels[\"train\"][\"pred\"]))\n    print(\"\\tVal\")\n    print(np.unique(labels[\"val\"][\"pred\"],return_counts=True))\n    print(classification_report(labels[\"val\"][\"true\"],labels[\"val\"][\"pred\"]))\n    print(\"\\n\\n\\n\")\n\nprint(\"Trained\\n\")\n# print(logger)\n\n# with open(\"./models/model_pair.pt\",\"wb\") as f: \n#     torch.save(model_pair,f)\n\ntorch.save(model_pair,\"model_pair.pt\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Classify_Emotion(nn.Module):\n    def __init__(self, input_size, output_size=7):\n        super().__init__()\n        self.layer = nn.Sequential(\n            nn.Linear(input_size, 2048),\n            nn.LeakyReLU(),\n            nn.Linear(2048, 1024),\n            nn.LeakyReLU(),\n            nn.Linear(1024, 512),\n            nn.LeakyReLU(),\n            nn.Linear(512, 256),\n            nn.Linear(256, output_size)\n        )\n    \n    def forward(self, x):\n        return self.layer(x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Classify_Emotion(4096).to(DEVICE)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_span={\n    \"train\":{\n        \"ID\":[],\n        \"emotion\":[],\n    },\n    \"val\":{\n        \"ID\":[],\n        \"emotion\":[],\n    }\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Training_Classify_Emotion\\n\")\nNUM_EPOCHS=10\nepsilon = 1e-6\n\nfor i in range(NUM_EPOCHS):\n    labels={\n        \"train\":{\n            \"pred\":[],\n            \"true\":[],\n            \"identifier\":[]\n        },\n        \"val\":{\n            \"pred\":[],\n            \"true\":[],\n            \"identifier\":[]\n        }\n    }\n    \n    input_span={\n        \"train\":{\n            \"ID\":[],\n            \"emotion\":[],\n        },\n        \"val\":{\n            \"ID\":[],\n            \"emotion\":[],\n        }\n    }\n    \n    train_loss=0\n    val_loss=0\n    batch_train=0\n    batch_val=0\n    \n    model.train()\n    \n    \n    for feature,pair,emotion,identifier in train_loader:\n\n        feature=feature.to(DEVICE)\n        pair=pair.to(DEVICE)\n        emotion=emotion.to(DEVICE)\n        identifier=identifier.to(DEVICE)\n\n        outputs=model_pair(feature)\n        outputs=outputs.view(-1, 2).float()\n        outputs=torch.argmax(outputs,dim=1)\n        mask=outputs==1\n        \n                \n        outputs=model(feature)\n        outputs=outputs.add(epsilon)\n        outputs=outputs.view(-1, 7).float()\n        emotion=emotion.view(-1).to(torch.long)\n        \n        outputs=outputs[mask]\n        emotion=emotion[mask]\n        identifier=identifier[mask]\n                \n        \n        labels[\"train\"][\"true\"]+=emotion.cpu().detach().numpy().tolist()\n        temp=torch.argmax(outputs,dim=1)\n        labels[\"train\"][\"pred\"]+=temp.cpu().detach().numpy().tolist()\n        labels[\"train\"][\"identifier\"]+=identifier.cpu().detach().numpy().tolist()\n        \n        \n\n        loss=criterion(outputs,emotion)\n        \n        batch_train+=1\n        \n#         if(not (torch.isnan(loss))):\n        train_loss+=loss.item()\n\n        optimizer.zero_grad()\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n        optimizer.step()\n    \n    model.eval()\n    \n    \n    for feature,pair,emotion,identifier in val_loader:\n\n        feature=feature.to(DEVICE)\n        pair=pair.to(DEVICE)\n        emotion=emotion.to(DEVICE)\n        identifier=identifier.to(DEVICE)\n\n        outputs=model_pair(feature)\n        outputs=outputs.view(-1, 2).float()\n        outputs=torch.argmax(outputs,dim=1)\n        mask=outputs==1\n        \n        outputs=model(feature)\n        outputs=outputs.add(epsilon)\n        outputs=outputs.view(-1, 7).float()\n        emotion=emotion.view(-1).to(torch.long)\n        \n        outputs=outputs[mask]\n        emotion=emotion[mask]\n        identifier=identifier[mask]\n        \n        \n        labels[\"val\"][\"true\"]+=emotion.cpu().detach().numpy().tolist()\n        temp=torch.argmax(outputs,dim=1)\n        labels[\"val\"][\"pred\"]+=temp.cpu().detach().numpy().tolist()\n        labels[\"val\"][\"identifier\"]+=identifier.cpu().detach().numpy().tolist()\n\n\n        loss=criterion(outputs,emotion)\n\n#         if(not (torch.isnan(loss))):\n        val_loss+=loss.item()\n        \n        batch_val+=1\n        \n    \n    print(\"Epoch->\",i)\n    print(\"\\tTrain->\",train_loss/batch_train,\"\\tVal->\",val_loss/batch_val)\n\n\n    print(\"\\tTrain\")\n    a=[]\n    b=[]\n    \n    for i in range (len(labels[\"train\"][\"true\"])):\n        true=labels[\"train\"][\"true\"][i]\n        pred=labels[\"train\"][\"pred\"][i]\n        identity=labels[\"train\"][\"identifier\"][i]\n        if(pred!=5):\n            a.append(true)\n            b.append(pred)\n            input_span[\"train\"][\"ID\"].append(identity)\n            input_span[\"train\"][\"emotion\"].append(pred)\n            \n   \n    print(classification_report(a,b))\n    \n    print(\"\\tVal\")\n    a=[]\n    b=[]\n    \n    for i in range (len(labels[\"val\"][\"true\"])):\n        true=labels[\"val\"][\"true\"][i]\n        pred=labels[\"val\"][\"pred\"][i]\n        identity=labels[\"val\"][\"identifier\"][i]\n        if(pred!=5):\n            a.append(true)\n            b.append(pred)\n            input_span[\"val\"][\"ID\"].append(identity)\n            input_span[\"val\"][\"emotion\"].append(pred)\n            \n    print(classification_report(a,b))\n    print(\"\\n\\n\\n\")\n\nprint(\"Trained\\n\")\n# print(logger)\n\n# with open(\"./models/model_emotion.pt\",\"wb\") as f: \n#     torch.save(model,f)\n    \ntorch.save(model,\"model_emotion.pt\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp=LoadSave(\"./data/span/input_span.pkl\")\ntemp.save(input_span)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}