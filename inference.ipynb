{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8229590,"sourceType":"datasetVersion","datasetId":4862531}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom transformers import BertTokenizer, BertModel\nfrom sklearn.metrics.pairwise import cosine_similarity\n\nfrom sklearn.preprocessing import OneHotEncoder\nimport json\nfrom copy import deepcopy as cpy\n\nfrom torch.utils.data import Dataset,DataLoader\nimport torch.nn as nn\n\nfrom sklearn.metrics import *\n\nimport gc\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-25T17:47:08.325549Z","iopub.execute_input":"2024-04-25T17:47:08.325930Z","iopub.status.idle":"2024-04-25T17:47:08.332596Z","shell.execute_reply.started":"2024-04-25T17:47:08.325896Z","shell.execute_reply":"2024-04-25T17:47:08.331434Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"DEVICE='cpu'\nRANDOM_SEED = 42\n\nimport os\nimport numpy as np\nimport random\n\nif torch.cuda.is_available():\n    DEVICE='cuda'\n    \ndef seed_all(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    \nseed_all(RANDOM_SEED)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:47:08.334381Z","iopub.execute_input":"2024-04-25T17:47:08.335013Z","iopub.status.idle":"2024-04-25T17:47:08.353515Z","shell.execute_reply.started":"2024-04-25T17:47:08.334976Z","shell.execute_reply":"2024-04-25T17:47:08.352613Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"import pickle\n\nclass LoadSave:\n    def __init__(self,path):\n        self.path=path\n\n    def load(self):\n        f = open(self.path, 'rb')\n        loaded_obj=pickle.load(f)\n        f.close()\n        return loaded_obj\n\n    def save(self,here):        \n        f=open(self.path, 'wb')\n        pickle.dump(here,f)\n        f.close()","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:47:08.354616Z","iopub.execute_input":"2024-04-25T17:47:08.354869Z","iopub.status.idle":"2024-04-25T17:47:08.362702Z","shell.execute_reply.started":"2024-04-25T17:47:08.354846Z","shell.execute_reply":"2024-04-25T17:47:08.361841Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"!pip install sentence_transformers ","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:47:08.365079Z","iopub.execute_input":"2024-04-25T17:47:08.365437Z","iopub.status.idle":"2024-04-25T17:47:20.844814Z","shell.execute_reply.started":"2024-04-25T17:47:08.365406Z","shell.execute_reply":"2024-04-25T17:47:20.843607Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: sentence_transformers in /opt/conda/lib/python3.10/site-packages (2.7.0)\nRequirement already satisfied: transformers<5.0.0,>=4.34.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.39.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.66.1)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (2.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.26.4)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.11.4)\nRequirement already satisfied: huggingface-hub>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (0.22.2)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (9.5.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2024.2.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.31.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (2023.12.25)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.4.3)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (1.4.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (3.2.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.15.1->sentence_transformers) (3.1.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\nS_Bert=SentenceTransformer(\"all-MiniLM-L6-v2\")","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:47:20.846617Z","iopub.execute_input":"2024-04-25T17:47:20.847016Z","iopub.status.idle":"2024-04-25T17:47:22.857918Z","shell.execute_reply.started":"2024-04-25T17:47:20.846978Z","shell.execute_reply":"2024-04-25T17:47:22.857070Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"class Data():\n    def __init__(self,load=True):\n        self.load=load\n        if(load):\n            return\n\n        with open(\"/kaggle/input/project-dataset/data/train.json\",\"r\") as f:\n            data=json.load(f)\n            \n        self.MAX_SENTENCES=35\n        self.UNKNOWN_SPEAKER=\"unknown\"\n        self.PADDED_SPEAKER=\"padded\" #handle_unknown='ignore'\n        self.UNKNOWN_EMOTION=\"undefined\"\n        self.UNKNOWN_CAUSE=2\n        self.emotion_map={\n            self.UNKNOWN_EMOTION:-1,\n            'disgust':0,\n            'joy':1,\n            'surprise':2,\n            'anger':3,\n            'fear':4,\n            'neutral':5,\n            'sadness':6\n        }\n        \n        self.speakers=set()\n        for conv in data:\n            for sent in conv[\"conversation\"]:\n                self.speakers.add(sent[\"speaker\"])\n        self.speakers.add(self.UNKNOWN_SPEAKER)\n        \n        speakers=list(self.speakers)\n        \n        self.speaker_encoder= OneHotEncoder(sparse=False,handle_unknown='ignore')\n        \n        self.speaker_encoder.fit([[label] for label in speakers])\n            \n        \n            \n    def processor(self,data):\n        final_data=[]\n        \n        for conv in data:\n            temp={\n                \"sentences\":[],\n                \"speakers\":[],\n                \"padded\":[]\n            }\n            \n            filled=len(conv[\"conversation\"])\n          \n            for sent in conv[\"conversation\"]:\n                temp[\"sentences\"].append(sent[\"text\"])\n                temp[\"padded\"].append(0)\n                if sent[\"speaker\"] in self.speakers:\n                    temp[\"speakers\"].append([sent[\"speaker\"]])\n                else:\n                    temp[\"speakers\"].append([self.UNKNOWN_SPEAKER])\n                \n            for _ in range(0,self.MAX_SENTENCES-filled):\n                temp[\"sentences\"].append(\" \")\n                temp[\"speakers\"].append([self.PADDED_SPEAKER])\n                temp[\"padded\"].append(1)\n                \n            temp[\"speakers\"]=self.speaker_encoder.transform(temp[\"speakers\"])\n            \n            temp[\"sentences\"]=S_Bert.encode(temp[\"sentences\"],show_progress_bar=False)\n            \n                \n                \n            temp[\"sentences\"]=temp[\"sentences\"][:self.MAX_SENTENCES]\n            temp[\"speakers\"]=temp[\"speakers\"][:self.MAX_SENTENCES]\n            temp[\"padded\"]=np.array(temp[\"padded\"][:self.MAX_SENTENCES])\n            temp[\"ID\"]=int(conv[\"conversation_ID\"])\n                \n            final_data.append(cpy(temp))\n           \n        return final_data\n            \n\n    def train_data(self): \n        with open(\"/kaggle/input/project-dataset/data/train.json\",\"r\") as f:\n            data=json.load(f)\n            \n        return self.processor(data)\n\n            \n    def val_data(self):\n        with open(\"/kaggle/input/project-dataset/data/test.json\",\"r\") as f:\n            data=json.load(f)\n        \n        return self.processor(data)\n    \n    def test_data(self):\n        with open(\"/kaggle/input/project-dataset/data/original/test.json\",\"r\") as f:\n            data=json.load(f)\n        \n        return self.processor(data)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:47:22.859075Z","iopub.execute_input":"2024-04-25T17:47:22.859344Z","iopub.status.idle":"2024-04-25T17:47:22.878979Z","shell.execute_reply.started":"2024-04-25T17:47:22.859322Z","shell.execute_reply":"2024-04-25T17:47:22.877939Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"data=Data(False)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:47:22.880202Z","iopub.execute_input":"2024-04-25T17:47:22.880565Z","iopub.status.idle":"2024-04-25T17:47:22.947634Z","shell.execute_reply.started":"2024-04-25T17:47:22.880502Z","shell.execute_reply":"2024-04-25T17:47:22.946844Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# val=data.val_data()\n\nval=data.test_data()","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:47:22.948663Z","iopub.execute_input":"2024-04-25T17:47:22.948937Z","iopub.status.idle":"2024-04-25T17:47:34.660284Z","shell.execute_reply.started":"2024-04-25T17:47:22.948914Z","shell.execute_reply":"2024-04-25T17:47:34.659318Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"class Samples(Dataset):\n    def __init__(self,data):\n        self.data=data      \n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self,idx):\n        return self.data[idx]","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:47:34.661594Z","iopub.execute_input":"2024-04-25T17:47:34.661941Z","iopub.status.idle":"2024-04-25T17:47:34.667736Z","shell.execute_reply.started":"2024-04-25T17:47:34.661909Z","shell.execute_reply":"2024-04-25T17:47:34.666754Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"class Emotion_Rep(nn.Module):\n    def __init__(self):\n        super().__init__()\n        SIZE=1024\n        self.lstm= nn.LSTM(input_size=384+283, hidden_size=SIZE, batch_first=True, bidirectional=True)\n        \n        self.layer= nn.Sequential(\n            nn.Linear(SIZE*2, 512),\n            nn.LeakyReLU(),\n            nn.Linear(512, 128),\n            nn.LeakyReLU(),\n            nn.Linear(128, 2),\n        )\n  \n\n    def forward(self, x, x1):\n        x=torch.cat((x,x1),dim=2)\n        x_ = self.lstm(x)[0]\n        x_ = self.layer(x_)\n\n        return x_\n    \n    def embedding(self,x, x1):\n        x=torch.cat((x,x1),dim=2)\n        return self.lstm(x)[0]\n    \nclass Cause_Rep(nn.Module):\n    def __init__(self):\n        SIZE=1024\n        super().__init__()\n        self.lstm= nn.LSTM(input_size=384+283, hidden_size=SIZE, batch_first=True, bidirectional=True)\n        \n        self.layer= nn.Sequential(\n            nn.Linear(SIZE*2, 512),\n            nn.LeakyReLU(),\n            nn.Linear(512, 128),\n            nn.LeakyReLU(),\n            nn.Linear(128, 2),\n        )\n\n\n    def forward(self, x, x1):\n        x=torch.cat((x,x1),dim=2)\n        x_ = self.lstm(x)[0]\n        x_ = self.layer(x_)\n\n        return x_\n    \n    def embedding(self,x, x1):\n        x=torch.cat((x,x1),dim=2)\n        return self.lstm(x)[0]","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:47:34.671103Z","iopub.execute_input":"2024-04-25T17:47:34.671412Z","iopub.status.idle":"2024-04-25T17:47:34.683212Z","shell.execute_reply.started":"2024-04-25T17:47:34.671388Z","shell.execute_reply":"2024-04-25T17:47:34.682405Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"emotion_model=Emotion_Rep().to(DEVICE)\ncause_model=Cause_Rep().to(DEVICE)\n\nwith open(\"/kaggle/input/project-dataset/models/Emotion_Rep.pt\",\"rb\") as f:\n    emotion_model=torch.load(f,map_location=DEVICE)\n    \nwith open(\"/kaggle/input/project-dataset/models/Cause_Rep.pt\",\"rb\") as f:\n    cause_model=torch.load(f,map_location=DEVICE)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:47:34.684197Z","iopub.execute_input":"2024-04-25T17:47:34.684475Z","iopub.status.idle":"2024-04-25T17:47:35.111104Z","shell.execute_reply.started":"2024-04-25T17:47:34.684452Z","shell.execute_reply":"2024-04-25T17:47:35.110312Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"val_embeddings_loader=DataLoader(Samples(val),batch_size=1)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:47:35.112170Z","iopub.execute_input":"2024-04-25T17:47:35.112533Z","iopub.status.idle":"2024-04-25T17:47:35.120222Z","shell.execute_reply.started":"2024-04-25T17:47:35.112508Z","shell.execute_reply":"2024-04-25T17:47:35.119397Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"val_embeddings=[]\n\nprint(\"Generating embeddings\\n\")\n\n\nemotion_model.eval()\ncause_model.eval()\n\n\nfor batch in val_embeddings_loader:\n    temp={}\n    temp[\"ID\"]=int(batch[\"ID\"][0].item())\n    inp=batch[\"sentences\"].to(DEVICE)\n    spk=batch[\"speakers\"].to(torch.long).to(DEVICE)\n    mask=batch[\"padded\"].to(DEVICE)\n    \n    mask=mask!=1\n    \n    inp=torch.unsqueeze(inp[mask],0)\n    spk=torch.unsqueeze(spk[mask],0)\n    \n    temp[\"emotion_embedding\"]=emotion_model.embedding(inp,spk).squeeze(dim=0).detach().cpu().numpy()\n    temp[\"cause_embedding\"]=cause_model.embedding(inp,spk).squeeze(dim=0).detach().cpu().numpy()\n    \n\n    outputs_emotion=emotion_model(inp,spk)\n    outputs_emotion=outputs_emotion.view(-1, 2).float()\n    \n    opt=torch.argmax(outputs_emotion,dim=1).cpu().detach().numpy().tolist()\n    temp[\"emotion_pred\"]=opt\n    \n    \n    \n    outputs_cause=cause_model(inp,spk)\n    outputs_cause=outputs_cause.view(-1, 2).float()\n\n    \n    opt=torch.argmax(outputs_cause,dim=1).cpu().detach().numpy().tolist()\n    temp[\"cause_pred\"]=opt\n    \n    val_embeddings.append(temp)\n\nprint(\"\\tGenerated Val\")\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:47:35.121352Z","iopub.execute_input":"2024-04-25T17:47:35.121640Z","iopub.status.idle":"2024-04-25T17:47:38.836724Z","shell.execute_reply.started":"2024-04-25T17:47:35.121616Z","shell.execute_reply":"2024-04-25T17:47:38.834362Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"Generating embeddings\n\n\tGenerated Val\n","output_type":"stream"}]},{"cell_type":"code","source":"val_conversations=[]\n\n    \nfor conv in val_embeddings:\n    temp={\n        \"features\":[],\n        \"indexes\":[]\n    }\n    \n    em_mask=np.array(conv[\"emotion_pred\"])==1\n    ca_mask=np.array(conv[\"cause_pred\"])==1\n    \n    em_ids=np.where(em_mask==True)[0]\n    ca_ids=np.where(ca_mask==True)[0]\n\n    \n    em_embed=conv[\"emotion_embedding\"][em_mask]\n    ca_embed=conv[\"cause_embedding\"][ca_mask]\n\n    \n    for em,em_id in zip(em_embed,em_ids):\n        for ca,ca_id in zip(ca_embed,ca_ids):\n            temp[\"features\"].append(np.concatenate([em,ca]))\n            temp[\"indexes\"].append([conv[\"ID\"],em_id+1,ca_id+1])\n                            \n    temp[\"features\"]=np.array(temp[\"features\"])\n    temp[\"indexes\"]=np.array(temp[\"indexes\"])\n    val_conversations.append(temp)\n        \n    ","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:47:38.838667Z","iopub.execute_input":"2024-04-25T17:47:38.839219Z","iopub.status.idle":"2024-04-25T17:47:39.209171Z","shell.execute_reply.started":"2024-04-25T17:47:38.839181Z","shell.execute_reply":"2024-04-25T17:47:39.208151Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"features_train=[]\nidentifier_train=[]\n\nfeatures_val=[]\nidentifier_val=[]","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:47:39.210534Z","iopub.execute_input":"2024-04-25T17:47:39.210862Z","iopub.status.idle":"2024-04-25T17:47:40.984404Z","shell.execute_reply.started":"2024-04-25T17:47:39.210832Z","shell.execute_reply":"2024-04-25T17:47:40.983530Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"class Samples_Classifier(Dataset):\n    def __init__(self,feature,identifier):\n        self.feature=torch.Tensor(feature)\n        self.identifier=torch.tensor(identifier)\n        \n    def __len__(self):\n        return len(self.feature)\n    \n    def __getitem__(self,idx):\n        return self.feature[idx],self.identifier[idx]","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:47:40.985622Z","iopub.execute_input":"2024-04-25T17:47:40.985937Z","iopub.status.idle":"2024-04-25T17:47:40.991922Z","shell.execute_reply.started":"2024-04-25T17:47:40.985910Z","shell.execute_reply":"2024-04-25T17:47:40.990954Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE=128\nprint(\"BatchMaking\")\n\n    \nfor i in val_conversations:\n    features_val+=i[\"features\"].tolist()\n    identifier_val+=i[\"indexes\"].tolist()\n    \nval_loader=DataLoader(Samples_Classifier(features_val,identifier_val),batch_size=BATCH_SIZE)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:47:40.993153Z","iopub.execute_input":"2024-04-25T17:47:40.993827Z","iopub.status.idle":"2024-04-25T17:47:54.711503Z","shell.execute_reply.started":"2024-04-25T17:47:40.993799Z","shell.execute_reply":"2024-04-25T17:47:54.710739Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"BatchMaking\n","output_type":"stream"}]},{"cell_type":"code","source":"class Classify_Pair(nn.Module):\n    def __init__(self, input_size, output_size=2):\n        super().__init__()\n        self.layer = nn.Sequential(\n            nn.Linear(input_size, 2048),\n            nn.LeakyReLU(),\n            nn.Linear(2048, 1024),\n            nn.LeakyReLU(),\n            nn.Linear(1024, 512),\n            nn.LeakyReLU(),\n            nn.Linear(512, 256),\n            nn.LeakyReLU(),\n            nn.Linear(256, output_size)\n        )\n    \n    def forward(self, x):\n        return self.layer(x)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:47:54.712639Z","iopub.execute_input":"2024-04-25T17:47:54.712896Z","iopub.status.idle":"2024-04-25T17:47:54.728983Z","shell.execute_reply.started":"2024-04-25T17:47:54.712874Z","shell.execute_reply":"2024-04-25T17:47:54.728044Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"model_pair = Classify_Pair(4096).to(DEVICE)\n\nwith open(\"/kaggle/input/project-dataset/models/model_pair.pt\",\"rb\") as f:\n    model_pair=torch.load(f,map_location=DEVICE)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:47:54.730148Z","iopub.execute_input":"2024-04-25T17:47:54.730433Z","iopub.status.idle":"2024-04-25T17:47:54.877795Z","shell.execute_reply.started":"2024-04-25T17:47:54.730410Z","shell.execute_reply":"2024-04-25T17:47:54.877019Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"class Classify_Emotion(nn.Module):\n    def __init__(self, input_size, output_size=7):\n        super().__init__()\n        self.layer = nn.Sequential(\n            nn.Linear(input_size, 2048),\n            nn.LeakyReLU(),\n            nn.Linear(2048, 1024),\n            nn.LeakyReLU(),\n            nn.Linear(1024, 512),\n            nn.LeakyReLU(),\n            nn.Linear(512, 256),\n            nn.Linear(256, output_size)\n        )\n    \n    def forward(self, x):\n        return self.layer(x)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:47:54.878809Z","iopub.execute_input":"2024-04-25T17:47:54.879090Z","iopub.status.idle":"2024-04-25T17:47:54.886247Z","shell.execute_reply.started":"2024-04-25T17:47:54.879065Z","shell.execute_reply":"2024-04-25T17:47:54.885307Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"model = Classify_Emotion(4096).to(DEVICE)\n\nwith open(\"/kaggle/input/project-dataset/models/model_emotion.pt\",\"rb\") as f:\n    model=torch.load(f,map_location=DEVICE)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:47:54.887600Z","iopub.execute_input":"2024-04-25T17:47:54.887877Z","iopub.status.idle":"2024-04-25T17:47:55.029065Z","shell.execute_reply.started":"2024-04-25T17:47:54.887854Z","shell.execute_reply":"2024-04-25T17:47:55.028112Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"print(\"Classifing_Emotion\\n\")\nNUM_EPOCHS=10\nepsilon = 1e-6\n\nlabels={\n    \"data\":{\n        \"pred\":[],\n        \"identifier\":[]\n    }\n}\n\ninput_span={\n    \"data\":{\n        \"ID\":[],\n        \"emotion\":[],\n    }\n}\n\n\nmodel_pair.eval()\nmodel.eval()\n\n\nfor feature,identifier in val_loader:\n\n    feature=feature.to(DEVICE)\n    identifier=identifier.to(DEVICE)\n\n    outputs=model_pair(feature)\n    outputs=outputs.view(-1, 2).float()\n    outputs=torch.argmax(outputs,dim=1)\n    mask=outputs==1\n\n    outputs=model(feature)\n    outputs=outputs.add(epsilon)\n    outputs=outputs.view(-1, 7).float()\n\n    outputs=outputs[mask]\n    identifier=identifier[mask]\n\n    temp=torch.argmax(outputs,dim=1)\n    labels[\"data\"][\"pred\"]+=temp.cpu().detach().numpy().tolist()\n    labels[\"data\"][\"identifier\"]+=identifier.cpu().detach().numpy().tolist()\n    \nfor i in range (len(labels[\"data\"][\"pred\"])):\n    pred=labels[\"data\"][\"pred\"][i]\n    identity=labels[\"data\"][\"identifier\"][i]\n    if(pred!=5):\n        input_span[\"data\"][\"ID\"].append(identity)\n        input_span[\"data\"][\"emotion\"].append(pred)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:47:55.030366Z","iopub.execute_input":"2024-04-25T17:47:55.030713Z","iopub.status.idle":"2024-04-25T17:47:55.548445Z","shell.execute_reply.started":"2024-04-25T17:47:55.030683Z","shell.execute_reply":"2024-04-25T17:47:55.547319Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"Classifing_Emotion\n\n","output_type":"stream"}]},{"cell_type":"code","source":"temp=LoadSave(\"./input_span.pkl\")\ntemp.save(input_span)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:47:55.549517Z","iopub.execute_input":"2024-04-25T17:47:55.549769Z","iopub.status.idle":"2024-04-25T17:47:55.554939Z","shell.execute_reply.started":"2024-04-25T17:47:55.549747Z","shell.execute_reply":"2024-04-25T17:47:55.554078Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"print(len(input_span['data'][\"ID\"]))","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:47:55.556179Z","iopub.execute_input":"2024-04-25T17:47:55.556575Z","iopub.status.idle":"2024-04-25T17:47:55.565714Z","shell.execute_reply.started":"2024-04-25T17:47:55.556545Z","shell.execute_reply":"2024-04-25T17:47:55.564970Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"1655\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import BertTokenizer, BertModel\nfrom transformers import T5ForConditionalGeneration, T5Tokenizer\n\nfrom copy import deepcopy as copy\nfrom sklearn.metrics import classification_report,f1_score,accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom transformers import pipeline, AutoModelForQuestionAnswering, AutoTokenizer\n\n\nfrom transformers import pipeline","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:48:08.059776Z","iopub.execute_input":"2024-04-25T17:48:08.060373Z","iopub.status.idle":"2024-04-25T17:48:18.870896Z","shell.execute_reply.started":"2024-04-25T17:48:08.060343Z","shell.execute_reply":"2024-04-25T17:48:18.870092Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stderr","text":"2024-04-25 17:48:09.564709: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-25 17:48:09.564830: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-25 17:48:09.662052: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"with open('/kaggle/input/project-dataset/data/original/train.json','r') as f:\n    data=json.load(f)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:48:21.340498Z","iopub.execute_input":"2024-04-25T17:48:21.341476Z","iopub.status.idle":"2024-04-25T17:48:21.424167Z","shell.execute_reply.started":"2024-04-25T17:48:21.341437Z","shell.execute_reply":"2024-04-25T17:48:21.423225Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"data_based_on_conv_id={}","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:48:23.720958Z","iopub.execute_input":"2024-04-25T17:48:23.721312Z","iopub.status.idle":"2024-04-25T17:48:23.725435Z","shell.execute_reply.started":"2024-04-25T17:48:23.721285Z","shell.execute_reply":"2024-04-25T17:48:23.724467Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"for i in range(2500):\n    data_based_on_conv_id[i+1]=[]","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:48:25.009106Z","iopub.execute_input":"2024-04-25T17:48:25.009470Z","iopub.status.idle":"2024-04-25T17:48:25.014805Z","shell.execute_reply.started":"2024-04-25T17:48:25.009435Z","shell.execute_reply":"2024-04-25T17:48:25.013676Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"for i in data:\n    data_based_on_conv_id[i['conversation_ID']]=i['conversation']","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:48:26.131859Z","iopub.execute_input":"2024-04-25T17:48:26.132214Z","iopub.status.idle":"2024-04-25T17:48:26.137754Z","shell.execute_reply.started":"2024-04-25T17:48:26.132187Z","shell.execute_reply":"2024-04-25T17:48:26.136797Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"with open('/kaggle/input/project-dataset/data/original/test.json','r') as f:\n    test_data=json.load(f)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:48:27.611747Z","iopub.execute_input":"2024-04-25T17:48:27.612589Z","iopub.status.idle":"2024-04-25T17:48:27.640355Z","shell.execute_reply.started":"2024-04-25T17:48:27.612557Z","shell.execute_reply":"2024-04-25T17:48:27.639566Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"for i in test_data:\n    data_based_on_conv_id[i['conversation_ID']]=i['conversation']","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:48:28.668134Z","iopub.execute_input":"2024-04-25T17:48:28.668956Z","iopub.status.idle":"2024-04-25T17:48:28.673531Z","shell.execute_reply.started":"2024-04-25T17:48:28.668920Z","shell.execute_reply":"2024-04-25T17:48:28.672596Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"emotion_cause_pair={}","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:48:33.357167Z","iopub.execute_input":"2024-04-25T17:48:33.357975Z","iopub.status.idle":"2024-04-25T17:48:33.361777Z","shell.execute_reply.started":"2024-04-25T17:48:33.357947Z","shell.execute_reply":"2024-04-25T17:48:33.360846Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"for i in range(2500):\n    emotion_cause_pair[i+1]=[]","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:48:39.661773Z","iopub.execute_input":"2024-04-25T17:48:39.662528Z","iopub.status.idle":"2024-04-25T17:48:39.667639Z","shell.execute_reply.started":"2024-04-25T17:48:39.662496Z","shell.execute_reply":"2024-04-25T17:48:39.666597Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"emotions={'disgust':0,\n            'joy':1,\n            'surprise':2,\n            'anger':3,\n            'fear':4,\n            'neutral':5,\n            'sadness':6}\n\nemotions_decode={0:'disgust',\n            1:'joy',\n            2:'surprise',\n            3:'anger',\n            4:'fear',\n            5:'neutral',\n            6:'sadness'}","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:48:43.887033Z","iopub.execute_input":"2024-04-25T17:48:43.887432Z","iopub.status.idle":"2024-04-25T17:48:43.892735Z","shell.execute_reply.started":"2024-04-25T17:48:43.887405Z","shell.execute_reply":"2024-04-25T17:48:43.891811Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"len(input_span['data']['ID'])","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:48:45.508484Z","iopub.execute_input":"2024-04-25T17:48:45.509104Z","iopub.status.idle":"2024-04-25T17:48:45.516143Z","shell.execute_reply.started":"2024-04-25T17:48:45.509072Z","shell.execute_reply":"2024-04-25T17:48:45.515137Z"},"trusted":true},"execution_count":57,"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"1655"},"metadata":{}}]},{"cell_type":"code","source":"emotion_cause_pair_2={}","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:48:46.710057Z","iopub.execute_input":"2024-04-25T17:48:46.710876Z","iopub.status.idle":"2024-04-25T17:48:46.714796Z","shell.execute_reply.started":"2024-04-25T17:48:46.710843Z","shell.execute_reply":"2024-04-25T17:48:46.713799Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"for i in range(2500):\n    emotion_cause_pair_2[i+1]=[]","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:48:47.737545Z","iopub.execute_input":"2024-04-25T17:48:47.737914Z","iopub.status.idle":"2024-04-25T17:48:47.743369Z","shell.execute_reply.started":"2024-04-25T17:48:47.737886Z","shell.execute_reply":"2024-04-25T17:48:47.742328Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"model_name = \"bert-large-uncased-whole-word-masking-finetuned-squad\"\nmodel = AutoModelForQuestionAnswering.from_pretrained(model_name).to(DEVICE)\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nnlp = pipeline(\"question-answering\",model=model, tokenizer=tokenizer)\n\nfor info in range(len(input_span['data']['ID'])):\n    conv_id=input_span['data']['ID'][info][0]\n    target_sent_idx=input_span['data']['ID'][info][1]\n    cause_sent_idx=input_span['data']['ID'][info][2]\n    cause=data_based_on_conv_id[conv_id][cause_sent_idx-1]['text']           # C question hai.\n    target=data_based_on_conv_id[conv_id][target_sent_idx-1]['text']\n    \n    emo=input_span['data']['emotion'][info]\n    \n    context=cause\n    question=\"which part of the context is cause for the utterance '\"+target+\"' with an \"+emotions_decode[emo]+\" emotion?\"\n    \n    answer = nlp(question=question, context=context)\n    \n    start_idx=answer['start']\n    end_idx=answer['end']\n    ans=answer['answer']\n    \n    pair1=str(target_sent_idx)+\"_\"+emotions_decode[emo]\n    pair2=str(cause_sent_idx)+\"_\"+ans\n    pair2_2=str(cause_sent_idx)+\"_\"+str(start_idx)+\"_\"+str(end_idx)\n    emotion_cause_pair[conv_id].append([pair1,pair2])\n    emotion_cause_pair_2[conv_id].append([pair1,pair2_2])\n\n    print(\"Remaining: \",len(input_span['data']['ID'])-info,\"\\t\\r\",end=\"\")\n    ","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:49:06.544126Z","iopub.execute_input":"2024-04-25T17:49:06.545142Z","iopub.status.idle":"2024-04-25T17:58:36.810855Z","shell.execute_reply.started":"2024-04-25T17:49:06.545109Z","shell.execute_reply":"2024-04-25T17:58:36.809920Z"},"trusted":true},"execution_count":60,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/443 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bab6c7bc55ec43818e3030b7b14f0551"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d197eca7e5384b198f4fb469c97d782f"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44e147847c734995a54a4ce7ff884155"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3bd256840d1546c7a4fd7a4737b77b63"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4fe0f97ed86d4c6184401adcf01fc644"}},"metadata":{}},{"name":"stdout","text":"Remaining:  1 \t\t\t\t\r","output_type":"stream"}]},{"cell_type":"code","source":"import json\n\n\nwith open('/kaggle/input/project-dataset/data/original/test.json','r') as f:\n    test_data=json.load(f)\n\n# print(test_data)\n\n\nfor i in range(len(test_data)):\n    conv_id=test_data[i]['conversation_ID']\n    test_data[i]['emotion-cause_pairs']=emotion_cause_pair_2[conv_id]\n\n\njson.dump(test_data, open(\"Subtask_1_pred.json\", 'w'))","metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:58:43.848098Z","iopub.execute_input":"2024-04-25T17:58:43.848475Z","iopub.status.idle":"2024-04-25T17:58:43.962199Z","shell.execute_reply.started":"2024-04-25T17:58:43.848437Z","shell.execute_reply":"2024-04-25T17:58:43.961229Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}